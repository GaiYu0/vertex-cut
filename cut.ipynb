{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaiyu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as eager\n",
    "import my\n",
    "import objectives\n",
    "import tf_gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "tf.enable_eager_execution(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "args.depth = 10\n",
    "args.device = '/cpu:0'\n",
    "# args.device = '/device:GPU:0'\n",
    "# args.graph = 'soc-Epinions1'\n",
    "# args.graph = 'soc-Slashdot0811'\n",
    "# args.graph = 'soc-Slashdot0902'\n",
    "args.graph = 'barabasi-albert-100-3'\n",
    "args.lambda_node = 0.0\n",
    "args.lambda_edge = 0.0\n",
    "args.lambda_entropy = 0.0\n",
    "args.n_features = 16\n",
    "args.n_iterations = 500\n",
    "args.n_machines = 10\n",
    "args.radius = 3\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--depth', type=int, default=10)\n",
    "# parser.add_argument('--device', type=str, default='/cpu:0')\n",
    "# parser.add_argument('--graph', type=str, default='soc-Epinions1')\n",
    "# parser.add_argument('--lambda_node', type=float, default=1)\n",
    "# parser.add_argument('--lambda_edge', type=float, default=1)\n",
    "# parser.add_argument('--lambda_entropy', type=float, default=1)\n",
    "# parser.add_argument('--n-features', type=int, default=16)\n",
    "# parser.add_argument('--n-iterations', type=int, default=500)\n",
    "# parser.add_argument('--n-machines', type=int, default=10)\n",
    "# parser.add_argument('--radius', type=int, default=3)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "keys = sorted(vars(args).keys())\n",
    "run_id = 'ipynb-' + '-'.join('%s-%s' % (key, str(getattr(args, key))) for key in keys if key != 'device')\n",
    "writer = tf.contrib.summary.create_file_writer('runs/' + run_id)\n",
    "writer.set_as_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.graph.startswith('barabasi-albert'):\n",
    "    n, m = tuple(map(int, args.graph.split('-')[-2:]))\n",
    "    g = nx.barabasi_albert_graph(n, m)\n",
    "else:\n",
    "    g = my.read_edgelist('data/' + args.graph, fill=True)\n",
    "adj = nx.adj_matrix(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(args.device):\n",
    "    objective = objectives.Objective(adj, args.n_machines, args.lambda_node, args.lambda_edge, args.lambda_entropy)\n",
    "    gnn = tf_gnn.GNN((1,) + (args.n_features,) * args.depth, args.n_machines, adj, args.radius)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(args.device):\n",
    "    x = tf.constant(adj.sum(1), dtype=tf.float32)\n",
    "    x -= tf.reduce_mean(x)\n",
    "    x /= tf.sqrt(tf.reduce_mean(tf.square(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 10]4.190932 4.190932 -2.286214 -2.223595 1.559521\n",
      "[iteration 20]3.919498 3.919498 -2.290181 -2.140514 1.393119\n",
      "[iteration 30]4.144146 4.144146 -2.291087 -2.216047 1.560906\n",
      "[iteration 40]4.313107 4.313107 -2.293209 -2.218606 1.739156\n",
      "[iteration 50]4.402010 4.402010 -2.301945 -2.243014 1.823789\n",
      "[iteration 60]3.998550 3.998550 -2.289599 -2.146967 1.451083\n",
      "[iteration 70]4.264457 4.264457 -2.298118 -2.211026 1.725836\n",
      "[iteration 80]4.226362 4.226362 -2.297187 -2.196095 1.690964\n",
      "[iteration 90]4.167989 4.167989 -2.296689 -2.180760 1.640067\n",
      "[iteration 100]4.181338 4.181338 -2.293306 -2.186884 1.648436\n",
      "[iteration 110]4.225783 4.225783 -2.292672 -2.197277 1.682503\n",
      "[iteration 120]4.273950 4.273950 -2.290241 -2.205857 1.718163\n",
      "[iteration 130]4.245172 4.245172 -2.286363 -2.195933 1.709426\n",
      "[iteration 140]4.099951 4.099951 -2.285414 -2.156809 1.604972\n",
      "[iteration 150]4.094145 4.094145 -2.283896 -2.154907 1.594812\n",
      "[iteration 160]4.027215 4.027215 -2.279845 -2.129882 1.537380\n",
      "[iteration 170]4.054701 4.054701 -2.279897 -2.137820 1.556395\n",
      "[iteration 180]4.148224 4.148224 -2.283489 -2.169814 1.636324\n",
      "[iteration 190]4.261750 4.261750 -2.282305 -2.202454 1.690549\n",
      "[iteration 200]4.004153 4.004153 -2.267395 -2.139620 1.448920\n",
      "[iteration 210]3.990741 3.990741 -2.265073 -2.137635 1.434603\n",
      "[iteration 220]4.044493 4.044493 -2.264961 -2.165479 1.454456\n",
      "[iteration 230]4.097524 4.097524 -2.248806 -2.169896 1.533957\n",
      "[iteration 240]4.090796 4.090796 -2.249616 -2.169635 1.493384\n",
      "[iteration 250]4.077488 4.077488 -2.250867 -2.169582 1.471138\n",
      "[iteration 260]4.064884 4.064884 -2.247778 -2.162844 1.477666\n",
      "[iteration 270]3.966075 3.966075 -2.245050 -2.136203 1.396756\n",
      "[iteration 280]3.922750 3.922750 -2.251340 -2.123679 1.367381\n",
      "[iteration 290]3.896897 3.896897 -2.259137 -2.114928 1.369316\n",
      "[iteration 300]3.896856 3.896856 -2.261116 -2.115159 1.389663\n",
      "[iteration 310]3.913775 3.913775 -2.263531 -2.122386 1.415251\n",
      "[iteration 320]3.981714 3.981714 -2.265733 -2.146741 1.479369\n",
      "[iteration 330]4.003943 4.003943 -2.266433 -2.151779 1.504911\n",
      "[iteration 340]3.974244 3.974244 -2.269013 -2.141166 1.471475\n",
      "[iteration 350]3.941558 3.941558 -2.268607 -2.127966 1.442790\n",
      "[iteration 360]3.925611 3.925611 -2.266666 -2.122936 1.432092\n",
      "[iteration 370]3.919731 3.919731 -2.265559 -2.120842 1.428276\n",
      "[iteration 380]3.897339 3.897339 -2.264854 -2.111551 1.410293\n",
      "[iteration 390]3.928490 3.928490 -2.267998 -2.123559 1.433731\n",
      "[iteration 400]3.962613 3.962613 -2.269480 -2.135046 1.459324\n",
      "[iteration 410]3.987319 3.987319 -2.271865 -2.142558 1.475018\n",
      "[iteration 420]4.015517 4.015517 -2.272376 -2.152276 1.499723\n",
      "[iteration 430]4.038122 4.038122 -2.275103 -2.160658 1.516509\n",
      "[iteration 440]4.088945 4.088945 -2.275876 -2.175975 1.566122\n",
      "[iteration 450]4.128648 4.128648 -2.273915 -2.183372 1.601343\n",
      "[iteration 460]4.138073 4.138073 -2.269761 -2.179946 1.611553\n",
      "[iteration 470]4.098258 4.098258 -2.265020 -2.162534 1.601498\n",
      "[iteration 480]3.982608 3.982608 -2.264850 -2.126824 1.513901\n",
      "[iteration 490]3.938277 3.938277 -2.263561 -2.111791 1.478505\n",
      "[iteration 500]3.958240 3.958240 -2.264384 -2.119227 1.494130\n"
     ]
    }
   ],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "with tf.device(args.device):\n",
    "    for i in range(args.n_iterations):\n",
    "        global_step.assign_add(1)\n",
    "        with tf.contrib.summary.record_summaries_every_n_global_steps(1):\n",
    "            with eager.GradientTape() as tape:\n",
    "                z = gnn(x, training=True)\n",
    "                rslt, r, b_node, b_edge, entropy = objective(z, training=True)\n",
    "            gradients = tape.gradient(rslt, gnn.variables)\n",
    "            optimizer.apply_gradients(zip(gradients, gnn.variables), global_step=tf.train.get_or_create_global_step())\n",
    "            \n",
    "            tf.contrib.summary.scalar('objective-log_p', rslt)\n",
    "            r, b_node, b_edge, entropy = objective(z)\n",
    "            rslt = r + args.lambda_node * b_node + args.lambda_edge * b_edge + args.lambda_entropy * entropy\n",
    "            tf.contrib.summary.scalar('objective', rslt)\n",
    "            tf.contrib.summary.scalar('replication-factor', r)\n",
    "            tf.contrib.summary.scalar('node-balancedness', b_node)\n",
    "            tf.contrib.summary.scalar('edge-balancedness', b_edge)\n",
    "            tf.contrib.summary.scalar('entropy', entropy)\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print('[iteration %d]%f %f %f %f %f' % (i + 1, rslt, r, b_node, b_edge, entropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ckpt = eager.Checkpoint(model=gnn)\n",
    "# ckpt.save('./models/gnn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

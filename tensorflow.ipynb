{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaiyu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import networkx as nx\n",
    "import tensorflow as tf # TODO use gpu\n",
    "import tensorflow.contrib.eager as tfe\n",
    "tf.enable_eager_execution()\n",
    "import my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "args.depth = 10\n",
    "args.device = '/cpu:0'\n",
    "args.graph = 'soc-Epinions1-reduced'\n",
    "args.n_features = 8\n",
    "args.n_machines = 10\n",
    "args.radius = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModule(tf.keras.Model):\n",
    "    def __init__(self, in_features, out_features, adj, nonlinear):\n",
    "        super().__init__()\n",
    "        self.adj = adj\n",
    "        self.deg = tf.reduce_sum(adj[0], 1, keepdims=True)\n",
    "        new_linear = lambda: nn.Parameter(th.randn(in_features, out_features / 2))\n",
    "        self.alpha1, self.alpha2, self.alpha3 = new_linear(), new_linear(), new_linear()\n",
    "        self.alpha4 = nn.ParameterList([new_linear() for a in adj])\n",
    "        self.beta1, self.beta2, self.beta3 = new_linear(), new_linear(), new_linear()\n",
    "        self.beta4 = nn.ParameterList([new_linear() for a in adj])\n",
    "        self.bn_alpha, self.bn_beta = nn.BatchNorm1d(out_features), nn.BatchNorm1d(out_features)\n",
    "        self.nonlinear = nonlinear\n",
    "    \n",
    "    def forward(self, x):\n",
    "        deg = self.deg * x\n",
    "        u = th.zeros_like(x) + th.mean(x, 1, keepdim=True)\n",
    "        adj = [th.mm(a, x) for a in self.adj]\n",
    "        alpha = th.mm(x, self.alpha1) + th.mm(deg, self.alpha1) + th.mm(u, self.alpha2) + \\\n",
    "            sum(th.mm(a, alpha) for alpha, a in zip(self.alpha4, adj))\n",
    "        alpha = self.bn_alpha(self.nonlinear(alpha))\n",
    "        beta = th.mm(x, self.beta1) + th.mm(deg, self.beta1) + th.mm(u, self.beta2) + \\\n",
    "            sum(th.mm(a, beta) for beta, a in zip(self.beta4, adj))\n",
    "        beta = self.bn_beta(beta)\n",
    "        return th.cat((alpha, beta), 1)\n",
    "\n",
    "class EdgeDense(tf.keras.Model):\n",
    "    def __init__(self, in_features, out_features, adj):\n",
    "        super().__init__()\n",
    "        self.adj = adj\n",
    "        self.out_features = out_features\n",
    "        for i in range(out_features):\n",
    "            setattr(self, 'dense%d' % i, tf.keras.layers.Dense(input_shape=(in_features,), units=1))\n",
    "    \n",
    "    def call(self, x):\n",
    "        z_list = []\n",
    "        for i in range(self.out_features):\n",
    "            z = getattr(self, 'dense%d' % i)(x)\n",
    "            z = tf.sparse_add(z * self.adj, tf.transpose(z) * self.adj)\n",
    "            z_list.append(tf.reshape(z.values, (-1, 1)))\n",
    "        z = tf.concat(z_list, 1)\n",
    "        return z\n",
    "\n",
    "class GNN(tf.keras.Model):\n",
    "    def __init__(self, features, n_classes, adj, radius, nonlinear, dense):\n",
    "        super().__init__()\n",
    "        adj = my.sparse_sp2th(adj).float()\n",
    "        if dense:\n",
    "            adj = adj.to_dense()\n",
    "        a, adj_list = adj, [adj]\n",
    "        for i in range(radius - 1):\n",
    "            a = th.mm(a, a)\n",
    "            adj_list.append(a)\n",
    "        self.module_list = nn.ModuleList([GNNModule(m, n, adj_list, nonlinear)\n",
    "                                          for m, n in zip(features[:-1], features[1:])])\n",
    "        self.linear = EdgeLinear(features[-1], n_classes, adj)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for module in self.module_list:\n",
    "            x = module(x)\n",
    "        x = self.linear(x)\n",
    "        x = F.softmax(x, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective:\n",
    "    def __init__(self, adj, n_machines):\n",
    "        n = tf.cast(adj.dense_shape[0], tf.int32)\n",
    "        indices = tf.cast(adj.indices, tf.int32)\n",
    "        s = tf.one_hot(indices[:, 0], n) + tf.one_hot(indices[:, 1], n)\n",
    "        self.s = tf.transpose(s)\n",
    "        self.n_machines = n_machines\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        y = tf.multinomial(x, num_samples=1)\n",
    "        y = tf.squeeze(y)\n",
    "        y = tf.one_hot(y, self.n_machines)\n",
    "        y = tf.matmul(self.s, y)\n",
    "        r = tf.reduce_sum(y)\n",
    "        p = (tf.reduce_sum(y, 1) + 1) / r\n",
    "        b = -tf.reduce_sum(p * tf.log(p))\n",
    "        objective = -(r + b) * tf.log(x)\n",
    "        return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = my.read_edgelist(args.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(args.device):\n",
    "# with tf.device('/device:GPU:0'):\n",
    "    adj = tf.cast(my.sparse_sp2tf(nx.adj_matrix(g)), tf.float32)\n",
    "    objective = Objective(adj, args.n_machines)\n",
    "    dense = EdgeDense(args.n_features, args.n_machines, adj)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    \n",
    "    x = tfe.Variable(tf.random_normal((adj.dense_shape[0], args.n_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(args.device):\n",
    "    with tfe.GradientTape() as tape:\n",
    "        x = objective(dense(x))\n",
    "\n",
    "    gradients = tape.gradient(x, dense.variables)\n",
    "    optimizer.apply_gradients(zip(gradients, dense.variables)) # TODO tf.train.get_or_create_global_step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
